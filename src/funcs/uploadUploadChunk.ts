/*
 * Code generated by Speakeasy (https://speakeasy.com). DO NOT EDIT.
 */

import { SDKCore } from "../core.js";
import { encodeJSON, encodeSimple } from "../lib/encodings.js";
import * as M from "../lib/matchers.js";
import { compactMap } from "../lib/primitives.js";
import { safeParse } from "../lib/schemas.js";
import { RequestOptions } from "../lib/sdks.js";
import { extractSecurity, resolveGlobalSecurity } from "../lib/security.js";
import { pathToFunc } from "../lib/url.js";
import { APIError } from "../models/errors/apierror.js";
import {
  ConnectionError,
  InvalidRequestError,
  RequestAbortedError,
  RequestTimeoutError,
  UnexpectedClientError,
} from "../models/errors/httpclienterrors.js";
import { SDKValidationError } from "../models/errors/sdkvalidationerror.js";
import {
  UploadChunkRequest,
  UploadChunkRequest$zodSchema,
  UploadChunkResponse,
  UploadChunkResponse$zodSchema,
} from "../models/uploadchunkop.js";
import { APICall, APIPromise } from "../types/async.js";
import { Result } from "../types/fp.js";

export enum UploadChunkAcceptEnum {
  applicationJsonAccept = "application/json",
  textHtmlAccept = "text/html",
}

/**
 * Upload a single chunk of a large file
 *
 * @remarks
 * Uploads a single chunk of a large file as part of a chunked upload process. This enables efficient upload of
 * large files with the ability to resume interrupted uploads. Each request uploads one chunk of the file.
 * It is required for any files that are larger than 100 MB. This is often relevant for video files, as they
 * tend to have larger file sizes. Minimum chunk size is 5 MB.
 */
export function uploadUploadChunk(
  client$: SDKCore,
  request: UploadChunkRequest,
  options?: RequestOptions,
): APIPromise<
  Result<
    UploadChunkResponse,
    | APIError
    | SDKValidationError
    | UnexpectedClientError
    | InvalidRequestError
    | RequestAbortedError
    | RequestTimeoutError
    | ConnectionError
  >
> {
  return new APIPromise($do(
    client$,
    request,
    options,
  ));
}

async function $do(
  client$: SDKCore,
  request: UploadChunkRequest,
  options?: RequestOptions & { acceptHeaderOverride?: UploadChunkAcceptEnum },
): Promise<
  [
    Result<
      UploadChunkResponse,
      | APIError
      | SDKValidationError
      | UnexpectedClientError
      | InvalidRequestError
      | RequestAbortedError
      | RequestTimeoutError
      | ConnectionError
    >,
    APICall,
  ]
> {
  const parsed$ = safeParse(
    request,
    (value$) => UploadChunkRequest$zodSchema.parse(value$),
    "Input validation failed",
  );
  if (!parsed$.ok) {
    return [parsed$, { status: "invalid" }];
  }
  const payload$ = parsed$.value;
  const body$ = encodeJSON("body", payload$.upload_request, { explode: true });

  const pathParams$ = {
    cloud_name: encodeSimple("cloud_name", client$._options.cloud_name, {
      explode: false,
      charEncoding: "percent",
    }),
    resource_type: encodeSimple("resource_type", payload$.resource_type, {
      explode: false,
      charEncoding: "percent",
    }),
  };
  const path$ = pathToFunc("/v1_1/{cloud_name}/{resource_type}/upload_chunked")(
    pathParams$,
  );

  const headers$ = new Headers(compactMap({
    "Content-Type": "application/json",
    Accept: options?.acceptHeaderOverride
      || "application/json;q=1, text/html;q=0",
    "Content-Range": encodeSimple("Content-Range", payload$.contentRange, {
      explode: false,
      charEncoding: "none",
    }),
    "X-Unique-Upload-Id": encodeSimple(
      "X-Unique-Upload-Id",
      payload$.xUniqueUploadId,
      { explode: false, charEncoding: "none" },
    ),
  }));
  const securityInput = await extractSecurity(client$._options.security);
  const requestSecurity = resolveGlobalSecurity(securityInput);

  const context = {
    baseURL: options?.serverURL ?? client$._baseURL ?? "",
    operationID: "uploadChunk",
    oAuth2Scopes: [],
    resolvedSecurity: requestSecurity,
    securitySource: client$._options.security,
    retryConfig: options?.retries
      || client$._options.retryConfig
      || { strategy: "none" },
    retryCodes: options?.retryCodes || [
      "429",
      "500",
      "502",
      "503",
      "504",
    ],
  };

  const requestRes = client$._createRequest(context, {
    security: requestSecurity,
    method: "POST",
    baseURL: options?.serverURL,
    path: path$,
    headers: headers$,
    body: body$,
    timeoutMs: options?.timeoutMs || client$._options.timeoutMs
      || -1,
  }, options);
  if (!requestRes.ok) {
    return [requestRes, { status: "invalid" }];
  }
  const req$ = requestRes.value;

  const doResult = await client$._do(req$, {
    context,
    errorCodes: [],
    retryConfig: context.retryConfig,
    retryCodes: context.retryCodes,
  });
  if (!doResult.ok) {
    return [doResult, { status: "request-error", request: req$ }];
  }
  const response = doResult.value;
  const responseFields$ = {
    HttpMeta: { Response: response, Request: req$ },
  };

  const [result$] = await M.match<
    UploadChunkResponse,
    | APIError
    | SDKValidationError
    | UnexpectedClientError
    | InvalidRequestError
    | RequestAbortedError
    | RequestTimeoutError
    | ConnectionError
  >(
    M.json(200, UploadChunkResponse$zodSchema, { key: "oneOf" }),
    M.text(302, UploadChunkResponse$zodSchema, {
      ctype: "text/html",
      key: "html_redirect",
    }),
    M.json([400, 401, 403], UploadChunkResponse$zodSchema, {
      key: "api_error",
    }),
  )(response, req$, { extraFields: responseFields$ });

  return [result$, { status: "complete", request: req$, response }];
}
